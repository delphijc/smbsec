# Chapter 7 – Summary

**Key Takeaways**
- Ethics: bias mitigation, transparency, accountability, privacy.
- Regulations: GDPR, CCPA, PCI‑DSS, NIST CSF, ISO/IEC 27001 – all require explainable AI, data minimization, and secure handling.
- Governance: AI usage policy, model governance board, version control (MLflow/DVC), change management, risk assessment.
- Auditing: model drift detection, explainability audits, compliance scans, incident logging.
- Data governance: catalog, consent, retention, encryption.
- HITL: override mechanism, feedback loop, analyst training.
- Future‑proofing: modular models, regulatory watch, ethical AI roadmap.

**Actionable Next Steps**
1. Draft an AI usage policy covering data handling, model lifecycle, and incident response.
2. Set up a model registry (MLflow or DVC) to store artifacts with metadata.
3. Implement drift detection scripts that monitor input distribution and trigger retraining.
4. Create a compliance audit script that scans logs for PII or policy violations.
5. Build an override UI component that logs analyst rationale.
6. Schedule quarterly reviews with a governance board to update policies.

**Next Chapter Preview**
- Chapter 8 will detail the hands‑on lab environment, including Docker‑Compose stacks for Elastic, Wazuh, OpenCTI, and the AI services.
